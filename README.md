# NEW LIST 2020 - 2021: Machine-Learning / Deep-Learning / AI -Tutorials

Hi - Thanks for dropping by!<br>
<br>
I will be updating this tutorials site on a <b>daily basis</b> adding all relevant topcis, including latest researches papers from internet such as [arxiv.org](https://arxiv.org), [BIORXIV - Specifically Neuroscience](https://www.biorxiv.org/collection/neuroscience) to name a few. <br>
<br>
More importantly the applications of ML/DL/AI into industry areas such as Transportation, Medicine/Healthcare etc. will be something I'll watch with keen interest and would love to share the same with you.
<br>
Finally, it is **YOUR** help I will seek to make it more useful and less boring, so please do suggest/comment/contribute!
<p align="center">
  <img src="https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/AI.png">
</p>

## Index

* [deep-learning](#deep-learning)
   * [UBER | Pyro](#uber-pyro-probabalistic-tutorials)
   * [Netflix | VectorFlow](#netflix-vectorflow-tutorials)
   * [PyTorch](#pytorch-tutorials)
   * [tensorflow](#tensor-flow-tutorials)
   * [theano](#theano-tutorials)
   * [keras](#keras-tutorials)
   * [caffe](#deep-learning-misc)
   * [Torch/Lua]()
   * [MXNET]()
   
* [scikit-learn](#scikit-learn)
* [statistical-inference-scipy](#statistical-inference-scipy)
* [pandas](#pandas)
* [matplotlib](#matplotlib)
* [numpy](#numpy)
* [python-data](#python-data)
* [kaggle-and-business-analyses](#kaggle-and-business-analyses)
* [spark](#spark)
* [mapreduce-python](#mapreduce-python)
* [amazon web services](#aws)
* [command lines](#commands)
* [misc](#misc)
* [notebook-installation](#notebook-installation)
* [Curated list of Deep Learning / AI blogs](#curated-list-of-deeplearning-blogs)
* [credits](#credits)
* [contributing](#contributing)
* [contact-info](#contact-info)
* [license](#license)

## deep-learning

IPython Notebook(s) and other programming tools such as Torch/Lua/D lang in demonstrating deep learning functionality.

### uber-pyro-probabalistic-tutorials
<p align="center">
  <img src="https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/pyro.png">
</p>

Additional PyRo tutorials:

* [pyro-examples/full examples](http://pyro.ai/examples/)
* [pyro-examples/Variational Autoencoders](http://pyro.ai/examples/vae.html)
* [pyro-examples/Bayesian Regression](http://pyro.ai/examples/bayesian_regression.html)
* [pyro-examples/Deep Markov Model](http://pyro.ai/examples/dmm.html)
* [pyro-examples/AIR(Attend Infer Repeat)](http://pyro.ai/examples/air.html)
* [pyro-examples/Semi-Supervised VE](http://pyro.ai/examples/ss-vae.html)
* [pyro-examples/GMM](http://pyro.ai/examples/gmm.html)
* [pyro-examples/Gaussian Process](http://pyro.ai/examples/gp.html)
* [pyro-examples/Bayesian Optimization](http://pyro.ai/examples/bo.html)
* [Full Pyro Code](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/tree/master/deep-learning/UBER-pyro)



### netflix-vectorflow-tutorials
<p align="center">
  <img src="https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/VectorFlow.png">
</p>

* [MNIST Example, running with Dlang](https://github.com/Netflix/vectorflow/tree/master/examples)

### pytorch-tutorials
<p align="center">
  <img src="https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/PyTorch.png">
</p>

| Level | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Beginners/Zakizhou](https://github.com/pytorch/tutorials/tree/master/beginner_source) | Learning the basics of PyTorch from Facebook. |
| [Intermedia/Quanvuong](https://github.com/pytorch/tutorials/tree/master/intermediate_source) | Learning the intermediate stuff about PyTorch of from Facebook. |
| [Advanced/Chsasank](https://github.com/pytorch/tutorials/tree/master/advanced_source) | Learning the advanced stuff about PyTorch of from Facebook. |
| [Learning PyTorch by Examples - Numpy, Tensors and Autograd](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/tree/master/pytorch) | At its core, PyTorch provides two main features an n-dimensional Tensor, similar to numpy but can run on GPUs AND automatic differentiation for building and training neural networks. |
| [PyTorch - Getting to know autograd.Variable, Gradient, Neural Network](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/pytorch/PyTorch%20NN%20Basics%20-%20Autograd%20Gradient%20Neural%20Network%20Loss%20Backprop.ipynb) | Here we start with ultimate basics of Tensors, wrap a Tensor with Variable module, play with nn.Module and implement forward and backward function. |


### tensor-flow-tutorials
<br/>
<p align="center">
  <img src="https://avatars0.githubusercontent.com/u/15658638?v=3&s=100">
</p>
Additional TensorFlow tutorials:

* [pkmital/tensorflow_tutorials](https://github.com/pkmital/tensorflow_tutorials)
* [nlintz/TensorFlow-Tutorials](https://github.com/nlintz/TensorFlow-Tutorials)
* [alrojo/tensorflow-tutorial](https://github.com/alrojo/tensorflow-tutorial)
* [BinRoot/TensorFlow-Book](https://github.com/BinRoot/TensorFlow-Book)

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [tsf-basics](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/1_intro/basic_operations.ipynb) | Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google. |
| [tsf-linear](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/linear_regression.ipynb) | Implement linear regression in TensorFlow. |
| [tsf-logistic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/logistic_regression.ipynb) | Implement logistic regression in TensorFlow. |
| [tsf-nn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/nearest_neighbor.ipynb) | Implement nearest neighboars in TensorFlow. |
| [tsf-alex](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/alexnet.ipynb) | Implement AlexNet in TensorFlow. |
| [tsf-cnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/convolutional_network.ipynb) | Implement convolutional neural networks in TensorFlow. |
| [tsf-mlp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/multilayer_perceptron.ipynb) | Implement multilayer perceptrons in TensorFlow. |
| [tsf-rnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/recurrent_network.ipynb) | Implement recurrent neural networks in TensorFlow. |
| [tsf-gpu](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/4_multi_gpu/multigpu_basics.ipynb) | Learn about basic multi-GPU computation in TensorFlow. |
| [tsf-gviz](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/graph_visualization.ipynb) | Learn about graph visualization in TensorFlow. |
| [tsf-lviz](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/loss_visualization.ipynb) | Learn about loss visualization in TensorFlow. |

### tensor-flow-exercises

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [tsf-not-mnist](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/1_notmnist.ipynb) | Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow. |
| [tsf-fully-connected](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/2_fullyconnected.ipynb) | Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow. |
| [tsf-regularization](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/3_regularization.ipynb) | Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow. |
| [tsf-convolutions](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/4_convolutions.ipynb) | Create convolutional neural networks in TensorFlow. |
| [tsf-word2vec](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/5_word2vec.ipynb) | Train a skip-gram model over Text8 data in TensorFlow. |
| [tsf-lstm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/6_lstm.ipynb) | Train a LSTM character model over Text8 data in TensorFlow. |

<br/>
<p align="center">
  <img src="http://www.deeplearning.net/software/theano/_static/theano_logo_allblue_200x46.png">
</p>

### theano-tutorials

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [theano-intro](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/intro_theano/intro_theano.ipynb) | Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation. |
| [theano-scan](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/scan_tutorial/scan_tutorial.ipynb) | Learn scans, a mechanism to perform loops in a Theano graph. |
| [theano-logistic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/intro_theano/logistic_regression.ipynb) | Implement logistic regression in Theano. |
| [theano-rnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/rnn_tutorial/simple_rnn.ipynb) | Implement recurrent neural networks in Theano. |
| [theano-mlp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/theano_mlp/theano_mlp.ipynb) | Implement multilayer perceptrons in Theano. |

<br/>
<p align="center">
  <img src="http://i.imgur.com/L45Q8c2.jpg">
</p>

### keras-tutorials

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| keras | Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano. |
| [setup](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/README.md) | Learn about the tutorial goals and how to set up your Keras environment. |
| [intro-deep-learning-ann](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1%20Introduction%20-%20Deep%20Learning%20and%20ANN.ipynb) | Get an intro to deep learning with Keras and Artificial Neural Networks (ANN). |
| [Perceptrons and Adaline](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1.1%20Perceptron%20and%20Adaline.ipynb) | Implement Peceptron and adaptive linear neurons. |
| [MLP and MNIST Data](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1.2%20MLP%20and%20MNIST.ipynb) | Classifying handwritten digits,implement MLP, train and debug ANN |
| [theano](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.2%20Introduction%20-%20Theano.ipynb) | Learn about Theano by working with weights matrices and gradients. |
| [keras-otto](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.3%20Introduction%20-%20Keras.ipynb) | Learn about Keras by looking at the Kaggle Otto challenge. |
| [ann-mnist](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.4%20(Extra)%20A%20Simple%20Implementation%20of%20ANN%20for%20MNIST.ipynb) | Review a simple implementation of ANN for MNIST using Keras. |
| [conv-nets](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.1%20Supervised%20Learning%20-%20ConvNets.ipynb) | Learn about Convolutional Neural Networks (CNNs) with Keras. |
| [conv-net-1](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.2.1%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20I.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 1. |
| [conv-net-2](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.2.2%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20II.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 2. |
| [keras-models](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.3%20Supervised%20Learning%20-%20Famous%20Models%20with%20Keras.ipynb) | Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras. |
| [auto-encoders](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/6.%20AutoEncoders%20and%20Embeddings/6.1.%20AutoEncoders%20and%20Embeddings.ipynb) | Learn about Autoencoders with Keras. |
| [rnn-lstm](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/7.%20Recurrent%20Neural%20Networks/7.1%20RNN%20and%20LSTM.ipynb) | Learn about Recurrent Neural Networks (RNNs) with Keras. |
| [lstm-sentence-gen](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/7.%20Recurrent%20Neural%20Networks/7.2%20LSTM%20for%20Sentence%20Generation.ipynb) |  Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras. |
| [nlp-deep-learning](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/6.%20AutoEncoders%20and%20Embeddings/6.2%20NLP%20and%20Deep%20Learning.ipynb) | Learn about NLP using ANN (Artificial Neural Networks. |
| [hyperparamter-tuning](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/5.%20HyperParameter%20Tuning%20and%20Transfer%20Learning/5.1%20HyperParameter%20Tuning.ipynb) | Hyperparamters tuning using keras-wrapper.scikit-learn |

### deep-learning-misc

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [deep-dream](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/deep-dream/dream.ipynb) | Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images. |

<br/>
<p align="center">
  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png">
</p>

## scikit-learn

IPython Notebook(s) demonstrating scikit-learn functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [intro](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-intro.ipynb) | Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |
| [knn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-intro.ipynb#K-Nearest-Neighbors-Classifier) | Implement k-nearest neighbors in scikit-learn. |
| [linear-reg](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb) | Implement linear regression in scikit-learn. |
| [svm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-svm.ipynb) | Implement support vector machine classifiers with and without kernels in scikit-learn. |
| [random-forest](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-random-forest.ipynb) | Implement random forest classifiers and regressors in scikit-learn. |
| [k-means](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-k-means.ipynb) | Implement k-means clustering in scikit-learn. |
| [pca](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-pca.ipynb) | Implement principal component analysis in scikit-learn. |
| [gmm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-gmm.ipynb) | Implement Gaussian mixture models in scikit-learn. |
| [validation](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-validation.ipynb) | Implement validation and model selection in scikit-learn. |

<br/>
<p align="center">
  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png">
</p>

## statistical-inference-scipy

IPython Notebook(s) demonstrating statistical inference with SciPy functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| scipy | SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. |
| [effect-size](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/effect_size.ipynb) | Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States. |
| [sampling](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/sampling.ipynb) | Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data. |
| [hypothesis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/hypothesis.ipynb) | Explore hypothesis testing by analyzing the difference of first-born babies compared with others. |

<br/>
<p align="center">
  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png">
</p>

## pandas

IPython Notebook(s) demonstrating pandas functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [pandas](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/pandas.ipynb) | Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series. |
| [github-data-wrangling](https://github.com/donnemartin/viz/blob/master/githubstats/data_wrangling.ipynb) | Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the [`Viz`](https://github.com/donnemartin/viz) repo. |
| [Introduction-to-Pandas](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.00-Introduction-to-Pandas.ipynb) | Introduction to Pandas. |
| [Introducing-Pandas-Objects](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.01-Introducing-Pandas-Objects.ipynb) | Learn about Pandas objects. |
| [Data Indexing and Selection](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.02-Data-Indexing-and-Selection.ipynb) | Learn about data indexing and selection in Pandas. |
| [Operations-in-Pandas](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.03-Operations-in-Pandas.ipynb) | Learn about operating on data in Pandas. |
| [Missing-Values](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.04-Missing-Values.ipynb) | Learn about handling missing data in Pandas. |
| [Hierarchical-Indexing](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.05-Hierarchical-Indexing.ipynb) | Learn about hierarchical indexing in Pandas. |
| [Concat-And-Append](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.06-Concat-And-Append.ipynb) | Learn about combining datasets: concat and append in Pandas. |
| [Merge-and-Join](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.07-Merge-and-Join.ipynb) | Learn about combining datasets: merge and join in Pandas. |
| [Aggregation-and-Grouping](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.08-Aggregation-and-Grouping.ipynb) | Learn about aggregation and grouping in Pandas. |
| [Pivot-Tables](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.09-Pivot-Tables.ipynb) | Learn about pivot tables in Pandas. |
| [Working-With-Strings](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.10-Working-With-Strings.ipynb) | Learn about vectorized string operations in Pandas. |
| [Working-with-Time-Series](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.11-Working-with-Time-Series.ipynb) | Learn about working with time series in pandas. |
| [Performance-Eval-and-Query](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.12-Performance-Eval-and-Query.ipynb) | Learn about high-performance Pandas: eval() and query() in Pandas. |

<br/>
<p align="center">
  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png">
</p>

## matplotlib

IPython Notebook(s) demonstrating matplotlib functionality.

| Notebook | Description |
|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
| [matplotlib](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/matplotlib.ipynb) | Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. |
| [matplotlib-applied](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/matplotlib-applied.ipynb) | Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots. |
| [Introduction-To-Matplotlib](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.00-Introduction-To-Matplotlib.ipynb) | Introduction to Matplotlib. |
| [Simple-Line-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.01-Simple-Line-Plots.ipynb) | Learn about simple line plots in Matplotlib. |
| [Simple-Scatter-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.02-Simple-Scatter-Plots.ipynb) | Learn about simple scatter plots in Matplotlib. |
| [Errorbars.ipynb](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.03-Errorbars.ipynb) | Learn about visualizing errors in Matplotlib. |
| [Density-and-Contour-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.04-Density-and-Contour-Plots.ipynb) | Learn about density and contour plots in Matplotlib. |
| [Histograms-and-Binnings](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.05-Histograms-and-Binnings.ipynb) | Learn about histograms, binnings, and density in Matplotlib. |
| [Customizing-Legends](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.06-Customizing-Legends.ipynb) | Learn about customizing plot legends in Matplotlib. |
| [Customizing-Colorbars](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.07-Customizing-Colorbars.ipynb) | Learn about customizing colorbars in Matplotlib. |
| [Multiple-Subplots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.08-Multiple-Subplots.ipynb) | Learn about multiple subplots in Matplotlib. |
| [Text-and-Annotation](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.09-Text-and-Annotation.ipynb) | Learn about text and annotation in Matplotlib. |
| [Customizing-Ticks](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.10-Customizing-Ticks.ipynb) | Learn about customizing ticks in Matplotlib. |
| [Settings-and-Stylesheets](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.11-Settings-and-Stylesheets.ipynb) | Learn about customizing Matplotlib: configurations and stylesheets. |
| [Three-Dimensional-Plotting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.12-Three-Dimensional-Plotting.ipynb) | Learn about three-dimensional plotting in Matplotlib. |
| [Geographic-Data-With-Basemap](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.13-Geographic-Data-With-Basemap.ipynb) | Learn about geographic data with basemap in Matplotlib. |
| [Visualization-With-Seaborn](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.14-Visualization-With-Seaborn.ipynb) | Learn about visualization with Seaborn. |

<br/>
<p align="center">
  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png">
</p>

## numpy

IPython Notebook(s) demonstrating NumPy functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [numpy](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/numpy.ipynb) | Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |
| [Introduction-to-NumPy](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.00-Introduction-to-NumPy.ipynb) | Introduction to NumPy. |
| [Understanding-Data-Types](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.01-Understanding-Data-Types.ipynb) | Learn about data types in Python. |
| [The-Basics-Of-NumPy-Arrays](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.02-The-Basics-Of-NumPy-Arrays.ipynb) | Learn about the basics of NumPy arrays. |
| [Computation-on-arrays-ufuncs](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.03-Computation-on-arrays-ufuncs.ipynb) | Learn about computations on NumPy arrays: universal functions. |
| [Computation-on-arrays-aggregates](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.04-Computation-on-arrays-aggregates.ipynb) | Learn about aggregations: min, max, and everything in between in NumPy. |
| [Computation-on-arrays-broadcasting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.05-Computation-on-arrays-broadcasting.ipynb) | Learn about computation on arrays: broadcasting in NumPy. |
| [Boolean-Arrays-and-Masks](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.06-Boolean-Arrays-and-Masks.ipynb) | Learn about comparisons, masks, and boolean logic in NumPy. |
| [Fancy-Indexing](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.07-Fancy-Indexing.ipynb) | Learn about fancy indexing in NumPy. |
| [Sorting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.08-Sorting.ipynb) | Learn about sorting arrays in NumPy. |
| [Structured-Data-NumPy](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.09-Structured-Data-NumPy.ipynb) | Learn about structured data: NumPy's structured arrays. |

<br/>
<p align="center">
  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png">
</p>

## python-data

IPython Notebook(s) demonstrating Python functionality geared towards data analysis.

| Notebook | Description |
|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|
| [data structures](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/structs.ipynb) | Learn Python basics with tuples, lists, dicts, sets. |
| [data structure utilities](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/structs_utils.ipynb) | Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions. |
| [functions](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/functions.ipynb) | Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools. |
| [datetime](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/datetime.ipynb) | Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta. |
| [logging](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/logs.ipynb) | Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler. |
| [pdb](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/pdb.ipynb) | Learn how to debug in Python with the interactive source code debugger. |
| [unit tests](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/unit_tests.ipynb) | Learn how to test in Python with Nose unit tests. |

<br/>
<p align="center">
  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png">
</p>

## kaggle-and-business-analyses

IPython Notebook(s) used in [kaggle](https://www.kaggle.com/) competitions and business analyses.

| Notebook | Description |
|-------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|
| [titanic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/kaggle/titanic.ipynb) | Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning. |
| [churn-analysis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/analyses/churn.ipynb) | Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.|

<br/>
<p align="center">
  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png">
</p>

## spark

IPython Notebook(s) demonstrating spark and HDFS functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|
| [spark](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/spark/spark.ipynb) | In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms. |
| [hdfs](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/spark/hdfs.ipynb) | Reliably stores very large files across machines in a large cluster. |

<br/>
<p align="center">
  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png">
</p>

## mapreduce-python

IPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|
| [mapreduce-python](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/mapreduce/mapreduce-python.ipynb) | Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and [mrjob](https://github.com/Yelp/mrjob) config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  [Disco](https://github.com/discoproject/disco/) is another python-based alternative.|

<br/>

<p align="center">
  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png">
</p>

## aws

IPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.


Also check out:

* [SAWS](https://github.com/donnemartin/saws): A Supercharged AWS command line interface (CLI).
* [Awesome AWS](https://github.com/donnemartin/awesome-aws): A curated list of libraries, open source repos, guides, blogs, and other resources.

| Notebook | Description |
|------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [boto](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#Boto) | Official AWS SDK for Python. |
| [s3cmd](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3cmd) | Interacts with S3 through the command line. |
| [s3distcp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3distcp) | Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster. |
| [s3-parallel-put](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3-parallel-put) | Uploads multiple files to S3 in parallel. |
| [redshift](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#redshift) | Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP). |
| [kinesis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#kinesis) | Streams data in real time with the ability to process thousands of data streams per second. |
| [lambda](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#lambda) | Runs code in response to events, automatically managing compute resources. |

<br/>
<p align="center">
  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png">
</p>

## commands

IPython Notebook(s) demonstrating various command lines for Linux, Git, etc.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [linux](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/linux.ipynb) | Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.|
| [anaconda](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#anaconda) | Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment. |
| [ipython notebook](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#ipython-notebook) | Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document. |
| [git](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#git) | Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows. |
| [ruby](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#ruby) | Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages. |
| [jekyll](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#jekyll) | Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server. |
| [pelican](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#pelican) | Python-based alternative to Jekyll. |
| [django](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#django) | High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include [Pyramid](https://github.com/Pylons/pyramid), [Flask](https://github.com/pallets/flask), [Tornado](https://github.com/tornadoweb/tornado), and [Bottle](https://github.com/bottlepy/bottle).

## misc

IPython Notebook(s) demonstrating miscellaneous functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [regex](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/misc/regex.ipynb) | Regular expression cheat sheet useful in data wrangling.|
[algorithmia](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/misc/Algorithmia.ipynb) | Algorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.|

## notebook-installation

### anaconda

Anaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.

Follow instructions to install [Anaconda](https://docs.continuum.io/anaconda/install) or the more lightweight [miniconda](http://conda.pydata.org/miniconda.html).

### dev-setup

For detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the [dev-setup](https://github.com/donnemartin/dev-setup) repo.

### running-notebooks

Note: If you intend to learn the hard way (preferred method)then I'd strongly advice to write as much code as you can yourself and not just run pre-written code. If you still want to test it, then do the following: 

To view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found [here.](http://ipython.org/notebook.html)

    $ git clone https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials.git
    $ cd Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials
    $ jupyter notebook
    

Notebooks tested with Python 3.7+

# March 2019 Machine Learning Study Path
## A complete ML study path, focused on TensorFlow and Scikit-Learn

This repository is intended to provide a **complete and organic learning path** to getting started with Machine Learning.
You will understand both theory and be able to apply it in practice, with hands-on project.

It does not require any previous knowledge, but being confident with programming and high school math is necessary to understand and implement Machine Learning concepts.

I **strongly recommend** to buy [**this**](https://www.amazon.it/Hands-Machine-Learning-Scikit-Learn-Tensorflow/dp/1491962291/ref=pd_sbs_14_1/260-9599700-1757805?_encoding=UTF8&pd_rd_i=1491962291&pd_rd_r=23993915-4513-11e9-ad92-43c54a5a8a65&pd_rd_w=QNr5b&pd_rd_wg=Si7Nj&pf_rd_p=37660d27-94f1-4ebe-be01-184b332a9b15&pf_rd_r=SF0KMBGABMY3T790JY7Z&psc=1&refRID=SF0KMBGABMY3T790JY7Z) phenomenal book: "Hands-On Machine Learning with Scikit-Learn and TensorFlow" by  OreillY, which inspired me and has driven most of the organization and hierarchy of the content listed above.

A part from this, **every content** listed here is open source and free, most of that coming from the world-renowned universities and open source associations. 

When we learn something new, especially if wide and complex, is necessary to avoid confusion, so 
I tried to create the next steps of the path preferring contents from the same context and authors, when possible.
When not possible, I collected both theory and examples, further some pointers to resources like "best practices for _______".

#### I organized the Path in 4 sections:

#### Prerequisites
- Python
- Jupyter Notebook
- The Math you need
- The Machine Learning landscape

#### Machine learning with Scikit-Learn
- Why Scikit-Learn?
- End-to-End Machine Learning project 
- Linear Regression 
- Classification
- Training models
- Support Vector Machines
- Decision Trees
- Ensemble Learning and Random Forest 
- Wrapping up and looking forward

#### Neural Networks with TensorFlow
- Why TensorFlow?
- Up and Running with TensorFlow
- ANN - Artificial Neural Networks 
- CNN - Convolutional Neural Networks
- RNN - Recurrent Neural Networks
- Training Networks: Best practices 
- AutoEncoders
- Reinforcement Learning
- Next steps

#### Utilities
- Machine Learning Projects 
- Data Science Tools
- Blogs / Youtube Channels / Websites worth taking a look!


So let's get started!

---------------------------------------------------------------

## Prerequisites

### Python
According to Sun Tzu:
> If you don't know Python, learn it yesterday!

Python is one of the most used and loved programming languages, and it's necessary to get things done in the Machine Learning field. Like most of the frameworks of the bigger Data Science field, TensorFlow is married with Python and Scikit-Learn is written in Python.  

First, let's [install Python 3](https://realpython.com/installing-python/) on your machine!

We are ready to start our journey! 

If you don't know the basics of Python, just start from [here](https://pythonprogramming.net/introduction-learn-python-3-tutorials/).\
Else if you know the syntax and you want to have a more solid Python background (recommended) take this Intermediate Python Course from [here](https://pythonprogramming.net/introduction-intermediate-python-tutorial/).\
If you are looking for tons of exercises to get your hands dirty and get experience with Python, check [here](https://www.w3resource.com/python-exercises/) and [here](https://www.practicepython.org/).

Once you're familiar with Python, take a look at [Numpy](https://docs.scipy.org/doc/numpy-1.13.0/user/whatisnumpy.html), an important module for math operations, that allows you to import in Python the [Tensor](https://www.kdnuggets.com/2018/05/wtf-tensor.html) data type, which is the most used in ML (especially when dealing with Neural Nets).
[It's not a matrix!](https://medium.com/@quantumsteinke/whats-the-difference-between-a-matrix-and-a-tensor-4505fbdc576c)
This is an awesome [Numpy Tutorial](http://cs231n.github.io/python-numpy-tutorial/).

I also recommend you to install [Pycharm Community Edition](https://www.jetbrains.com/pycharm/download/#section=windows), a complete IDE for Python development, and [set a new Python virtual environment](https://www.jetbrains.com/help/pycharm/creating-virtual-environment.html) for our experiments.

### Jupyter Notebook
Directly from [here](https://jupyter.org/): "The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more."
Working with data means -> a lot of expriments. And to document experiments, and organize them in a valuable way to get insights, you definitely need to use Jupyter Notebook during your journey. [Why](http://blendedlearning.blogs.brynmawr.edu/what-are-jupyter-notebooks-why-would-i-want-to-use-them/)?


### The math you need
Who tells that the math behind Machine Learning is hard... it's not so wrong! But you have to consider that every time you're going to use it, it will be handled by the machine for you! So, the important is to grasp the main math concepts and recognize limits and applications of those. No one is going to ask you to calculate a gradient by hand! So, even if you are not familiar with these concepts, check them, because they are the reason behind everything.

With these three resources, you'll get out the most of what you really need to understand things deeply.

A top course about linear algebra is [here](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/).\
Integrate with basic probabilities and statistic concepts [here](https://www.edx.org/course/introduction-to-probability-0).\
The most of the remaining math you need [here](https://explained.ai/matrix-calculus/index.html#sec4.5).


### The machine learning Landscape
Directly from the book cited earlier, this is the most concise and illuminating overview of **what is** and **when you need** machine learning. Let's stop use buzzwords!
Check it [here](https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/ch01.html).

----------------------------------------------------------------

## Machine Learning with Scikit-Learn

To install Scikit-Learn 

``` 
python pip install -U scikit-learn
```

If you encounter some problems, it may be because you don't have the last version of pip. So n the same folder run:

```
 python -m pip install --upgrade pip
```

### Why Scikit-Learn
[Scikit-Learn](https://scikit-learn.org/stable/) one of the most complete, mature and well-documented library for Machine Learning tasks. It comes out-of-the-box with powerful and advanced models and offers facility functions for the data science process. 
We'll learn and use other modules along the road, for a quick usage just look at their official documentation. 


### End-to-End Machine Learning project 
For a first taste, i suggest you to go through this Kaggle notebook, which is the most classic example of ML task. The goal is trying to predict if a Titanic passenger would have been most likely to survive or not. Many things will be unclear for now, but don't worry, they will be all explained comprehensively later. Is nice to get the picture of the "applied" project, going through the classical steps of the applied Machine Learning (problem framing, data exploration, question formulation...).

The notebook is on [Kaggle](https://www.kaggle.com/), the go-to platform for ML and general Data Science projects, which provides a lot of free datasets and offers interesting challenges and ML model experiments.

[This](https://www.kaggle.com/startupsci/titanic-data-science-solutions) is the notebook: Read it, trying to get the big picture of the process, because some details, functions and code will be clearer later.

### Linear Regression
This is the simplest form of Machine Learning, and the starting point for everyone interested in predicting outcomes from a dataset.
Check [here](https://www.youtube.com/watch?v=W46UTQ_JDPk&list=PLoR5VjrKytrCv-Vxnhp5UyS1UjZsXP0Kj&index=2) the theoretical lesson from Andrew NG and then go through these examples, from the simplest to the most complete.
[This](https://www.geeksforgeeks.org/ml-normal-equation-in-linear-regression/) is the math behind Linear Regression.
- [Example 1](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)
- [Example 2](https://bigdata-madesimple.com/how-to-run-linear-regression-in-python-scikit-learn/)
- [Example 3](https://www.geeksforgeeks.org/linear-regression-python-implementation/)

### Classification
Classification is one of the most important ML tasks, and it consists of predicting **an outcome given an input**, classifying it among differente possibilities. For example, given handwritten numbers, guess what the number is, with the lowest error rate possible.
The simplest case is binary classification (Yes or No, Survived or Not Survived), have a look [here](https://machinelearningmastery.com/make-predictions-scikit-learn/).
Check [here](https://towardsdatascience.com/building-a-logistic-regression-in-python-301d27367c24) a brief explanation of the theory of logistic regression algorithm for classification, and check [here](https://www.youtube.com/watch?v=VCJdg7YBbAQ) for a deeper comprehension (using the Titanic dataset).
You can use a lot of different ML models to classify things, even neural networks! For now, just take a look [here](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html), where you see an example of comparison among different models accuracy and recall.
[Here](https://medium.com/thalus-ai/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b) you have an article about the metrics used to **evaluate** your classifiers.

### Training models
Here i grouped some of the techniques used in ML tasks to train the models.
In this Google Crash Course you find:
- [Gradient Descent](https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent)
- [Learning Rate](https://developers.google.com/machine-learning/crash-course/reducing-loss/learning-rate)
- [SGD](https://developers.google.com/machine-learning/crash-course/reducing-loss/stochastic-gradient-descent)
- [Regularization](https://www.youtube.com/watch?v=Q81RR3yKn30)

### Support Vector Machines
This is another classical algorithm to create ML models.
[Here](https://www.youtube.com/watch?v=_PwhiWxHK8o) you have the explanation of the theory, and [here](https://www.youtube.com/watch?v=g8D5YL6cOSE) a more pratical approach. Check both.
[Here](https://scikit-learn.org/stable/modules/svm.html) is a very good explanation + practice application in Scikit-Learn.

### Decision Trees
Decision Trees are one of the most simple but effective idea behind predicting outcomes, and they're used in many ways (i.e. Random Forest). Check [here](https://www.youtube.com/watch?v=eKD5gxPPeY0&list=PLBv09BD7ez_4temBw7vLA19p3tdQH6FYO) and go through the playlist to get a theoretical overview of Decision Trees (ID3).
[Here](https://scikit-learn.org/stable/modules/tree.html) you have the pratical application of ID3.
Here you have a some end-to-end examples, with  Scikit-Learn:
- [Example 1](https://www.youtube.com/watch?v=9YcMzsFvfxU) 
- [Example 2](https://www.youtube.com/watch?v=RmajweUFKvM)
- [Example 3](http://dataaspirant.com/2017/02/01/decision-tree-algorithm-python-with-scikit-learn/)

### Ensemble Learning and Random Forest 
The idea of Ensemble Learning is to leverage all the different features, pro and cons of several ML models to obtain a group of "voters" that, for each prediction, gives you the most likely outcome, voted by different classifiers (SVM, ID3, maybe Logistic Regression). 
[Here](https://www.youtube.com/watch?v=9VmKYwX_U7s) you find the basics of the ensemble learning approach, and [here](https://www.youtube.com/watch?v=3kYujfDgmNk) you find the most classic of them, the Random Forest. Altough the idea is simple, this ensemble model came up really effective tackling even some "hard" classification problems, or with a lot of data.  

[Here](https://scikit-learn.org/stable/modules/ensemble.html) you get a complete overview of the best practices for ensemble learning, and [here](https://towardsdatascience.com/random-forest-in-python-24d0893d51c0) you find an example of Random Forest with Scikit-Learn. Both link come with a bunch of useful techniques touse in practice. 

### Wrapping up and looking forward
Now, if you followed all the steps and explored all the resources i posted, you're likely to be mode confident with Machine Learning and have a general idea of the things. Of course you need to explore and learn more, because this field is changing and enhancing techniques and approaches day-by-day! All the algorithm we've seen are widely used in the Data Science and Analytics field, but there are some complex tasks where they fail or give really poor performances. Now we are ready to fall down in the **deep** rabbit hole, trying to understand how Neural Network and in general Deep Learning can help tackling big problem with millions of parameters and variables. 
[Why use Deep Learning over classical ML algorithms?](https://towardsdatascience.com/why-deep-learning-is-needed-over-traditional-machine-learning-1b6a99177063)

-----------------------------------------------------------------

## Neural Networks with TensorFlow
In this section we'll follow a track that will bring us to zero knowledge of neural network to fully understand them, thanks to the Stanford University Deep Learning course and some tutorials i've searched over the internet. Some of them come from Google, other from Stanford or Cambridge university, and you will learn to leverage neural networks (ANN, CNN, RNN) for several kind of ML tasks.
These are [some use cases](https://www.digitaldoughnut.com/articles/2017/march/top-5-use-cases-of-tensorflow) of using TensorFlow for ML tasks. 

The theory and the applications of the Neural Networks are not too easy to get at a first look. Because of that, you'll need to pass again through tutorials and videos, to ensure a fully comprehension of the coming topics. Because of that, I spent a decent amount of time trying to understand (reading paths like this, articles, offical forums, related subreddits) which was **the most effective way** to deeply learn the concepts, formulas, tradeoffs...
I came up with this approach, but you can tweak it as you prefer, because every brain is different.

> After taking the TensorFlow section
> 3 phases iterative cycle:

>- 1 Get an idea of the main concepts through **an entire pass** of this [Stanford course](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv), don't care too much on math explanations, focus on the **what and why**

>- 2 Deeply explore **one topic at time**, with theory + tutorials + examples (e.g. RNN theory + RNN tutorials + RNN examples)
>with the links and resources of the topic section of the guide.

>- 3 After iterating the 2 phase for each topic, walk again through the entire Stanford course. This time you can fully understand all  the formulas, connecting them and catching also the "math flow" of the course.

This iterative process (1-2-2-2-2.....-3) can be repeated may times as you want, and will probably construct in your mind a nice **general schema** of the things. In each complete iteration you can drop one or more topics, and focus on the ones that are more interesting to you or not so clear.

In each section i've put content for the first time you arrive there (during the first complete iteration), and some content for next time you arrive there (after the 3 phase).

The structure follows the track proposed by the Stanford awesome course. You find the slides [here](http://cs231n.stanford.edu/slides/2018/).

[This](http://introtodeeplearning.com/) is an alternative course from MIT, more or less the same contents. It's worth watching it to compare and have a differente point of view on the things, besides listening 2X the best professors of the world exploring each topic.  

This is the [**Book**](https://www.deeplearningbook.org/) I refer to in each section.

### Why TensorFlow?
Created by the [Google Brain](https://ai.google/research/teams/brain) team, [TensorFlow](https://www.tensorflow.org/) is an open source library for numerical computation and large-scale machine learning. TensorFlow bundles together a slew of machine learning and deep learning (aka neural networking) models and algorithms and makes them useful by way of a common metaphor. It uses Python to provide a convenient front-end API for building applications with the framework, while executing those applications in high-performance C++.
TensorFlow is the de-facto standard for the major industry-sized company that need to implement Machine Learning algorithms. Is built for scaling, with really cool features to parallelize training over multiple GPU's or devices.

### Up and Running with TensorFlow
Assuming you have [Python stored in the variable PATH](https://helpdeskgeek.com/windows-10/add-windows-path-environment-variable/), to install the Tensorflow library you just need to open a terminal inside you Python installation folder and run this command. 

``` 
python pip install tensorflow
```

The first read i recommend you is [this](https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/).
The second thing to do is to follow this [Introduction to TensorFlow](https://www.youtube.com/watch?v=tYYVSEHq-io) directly from the **awesome** [Google Education](https://ai.google/education/) page.
Again, some theoretical concepts might be unclear, but focus on how the TensorFlow library and process are conceived. 
[This](https://medium.com/@camrongodbout/tensorflow-in-a-nutshell-part-one-basics-3f4403709c9d) is a good resume of the latter.
[Another beginner tutorial from google](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0).
[This](https://www.youtube.com/watch?v=k5c-vg4rjBw&t=246s) is about the TensorFlow 2.0 update. 

Now you're most likely familiar with **TensorFlow as a tool**, and it's time to understand **how to use** it to build large scale Neural Networks. 
 
### ANN - Artificial Neural Networks 
_First look (in order):_
- [This video](https://www.youtube.com/watch?v=v2tKoymKIuE).
- [This is your bible](http://neuralnetworksanddeeplearning.com/chap1.html), understand it totally.
- [This is a gem](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.85356&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) and read [this](https://www.guru99.com/artificial-neural-network-tutorial.html) from the authors.
- [This](https://www.youtube.com/watch?v=o64FV-ez6Gw&t=540s) is a really fast-talking guy implementing a Neural Network library from scratch, super useful to understand how is implemented the core of NN in Python. You can imagine that each existing framework is just an enormous expansione of this concept-library.
- [This](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/) is a step-by-step backpropagation example with calculus.

_Second pass:_
- [ANN Chapter](https://www.deeplearningbook.org/contents/mlp.html).

_Tips & Best practices:_
[1](https://developers.google.com/machine-learning/crash-course/training-neural-networks/best-practices), [2](https://hackernoon.com/8-deep-learning-best-practices-i-learned-about-in-2017-700f32409512), [3](https://towardsdatascience.com/10-things-to-think-about-before-starting-to-code-your-deep-neural-network-65094a1e7c08), [4](https://towardsdatascience.com/how-to-increase-the-accuracy-of-a-neural-network-9f5d1c6f407d), [5](https://www.reddit.com/r/MachineLearning/comments/abj1mc/d_notes_on_why_deep_neural_networks_are_able_to/), [6](https://www.reddit.com/r/MachineLearning/comments/abj1mc/d_notes_on_why_deep_neural_networks_are_able_to/), [7](http://karpathy.github.io/neuralnets/), [8](https://medium.com/cracking-the-data-science-interview/a-gentle-introduction-to-neural-networks-for-machine-learning-d5f3f8987786).

### CNN - Convolutional Neural Networks
_First look (in order):_
- [Here](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/) is an awesome deep explanation. 
- [Here](https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8) another super good one.
- [Here](https://www.datacamp.com/community/tutorials/cnn-tensorflow-python) is serious CNN tutorial with TensorFlow.

_Second pass:_
- [CNN Chapter](https://www.deeplearningbook.org/contents/convnets.html).

_Tips & Best practices:_
[1](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/), [2](https://www.topbots.com/14-design-patterns-improve-convolutional-neural-network-cnn-architecture/), [3](https://arxiv.org/abs/1709.02601), [4](https://de.mathworks.com/matlabcentral/answers/362024-convolutional-neural-networks-what-is-the-best-practice-training-approach-using-graphics-cards), [5](http://www.academia.edu/4057996/Best_Practices_for_Convolutional_Neural_Networks_Applied_to_Visual_Document_Analysis), [6](https://www.microsoft.com/en-us/research/publication/best-practices-for-convolutional-neural-networks-applied-to-visual-document-analysis/), [7](https://missinglink.ai/guides/neural-network-concepts/neural-networks-image-recognition-methods-best-practices-applications/), [8](https://machinelearningmastery.com/best-practices-document-classification-deep-learning/).

### RNN - Recurrent Neural Networks
_First look (in order):_
- [Here](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) a gentle but detailed explanation.
- [Here](https://www.superdatascience.com/blogs/the-ultimate-guide-to-recurrent-neural-networks-rnn) another interesting explanation.
- [Here](https://www.youtube.com/watch?v=9zhrxE5PQgY) a video with a more pratical approach.
- [Here](https://becominghuman.ai/a-noobs-guide-to-implementing-rnn-lstm-using-tensorflow-1907a5bbb1fa) a guide to implement RNN in TensorFlow.
- [Here](https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767) a 7 pages blog post regarding the TensorFlow implementation.

_Second pass:_
- [RNN Chapter](https://www.deeplearningbook.org/contents/rnn.html)

_Tips & Best practices:_
[1](https://danijar.com/tips-for-training-recurrent-neural-networks/), [2](https://svail.github.io/rnn_perf/), [3](https://towardsdatascience.com/rnn-training-tips-and-tricks-2bf687e67527), [4](http://slazebni.cs.illinois.edu/spring17/lec20_rnn.pdf), [5](https://www.quora.com/What-are-the-best-practices-for-choosing-hidden-state-size-in-RNNs), [6](https://www.quora.com/Can-recurrent-neural-networks-with-LSTM-be-used-for-time-series-prediction), [7](https://www.reddit.com/r/MachineLearning/comments/5ogbd5/d_training_lstms_in_practice_tips_and_tricks/).
 
### Training Networks: Best practices 
_First look (in order):_
I **strongly recommend** you to refer to [this page](http://cs231n.github.io/) from Stanford and go through all the Module 1 and 2.
I put also here a list of the various topic to explore when talking about _how to train NN in real life applications_.

- Overfitting vs Underfitting: [1](https://keeeto.github.io/blog/bias_variance/), [2](https://cran.r-project.org/web/packages/keras/vignettes/tutorial_overfit_underfit.html), [3](https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/), [4](https://medium.com/greyatom/what-is-underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6803a989c76), [5](https://elitedatascience.com/overfitting-in-machine-learning). 
- Vanishing/Exploding Gradient: [1](https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb), [2](https://machinelearningmastery.com/exploding-gradients-in-neural-networks/), [3](https://hackernoon.com/exploding-and-vanishing-gradient-problem-math-behind-the-truth-6bd008df6e25), [4](https://www.jefkine.com/general/2018/05/21/2018-05-21-vanishing-and-exploding-gradient-problems/), [5](https://medium.com/@prateekvishnu/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528).
- Transfer Learning: [1](https://medium.com/analytics-vidhya/reusing-a-pre-trained-deep-learning-model-on-a-new-task-transfer-learning-1c0a25a92dfb), [2](https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/), [3](https://jjallaire.github.io/deep-learning-with-r-notebooks/notebooks/5.3-using-a-pretrained-convnet.nb.html), [4](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a), [5](https://machinelearningmastery.com/transfer-learning-for-deep-learning/).
- Faster Optimizers: [1](http://ruder.io/optimizing-gradient-descent/), [2](https://www.jeremyjordan.me/nn-learning-rate/), [3](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1), [4](https://towardsdatascience.com/learning-rate-scheduler-d8a55747dd90). 
- Avoiding Overfitting through Regularization: [1](https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a), [2](https://codeburst.io/what-is-regularization-in-machine-learning-aed5a1c36590), [3](https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/), [4](https://machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/).

_Second pass:_
- [Google best practices](https://developers.google.com/machine-learning/guides/rules-of-ml/).
- [Regularizaton Chapter](https://www.deeplearningbook.org/contents/regularization.html).
- [Optimization Chapter](https://www.deeplearningbook.org/contents/optimization.html).
- [Pratical Methodology Chapter](https://www.deeplearningbook.org/contents/guidelines.html).
 

### AutoEncoders
_First look (in order):_
- [Here](https://www.quora.com/What-is-an-auto-encoder-in-machine-learning) you find a first read.
- [This](https://towardsdatascience.com/deep-inside-autoencoders-7e41f319999f) is your second recommended read.
- [This](https://www.youtube.com/watch?v=vfnxKO2rMq4) is a lecture from Andrew NG.
- I give also you some examples: [1](https://www.guru99.com/autoencoder-deep-learning.html), [2](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/autoencoder.py), [3](https://towardsdatascience.com/deep-autoencoders-using-tensorflow-c68f075fd1a3), [4](http://machinelearninguru.com/deep_learning/tensorflow/neural_networks/autoencoder/autoencoder.html).

_Second pass:_
[AutoEncoders Chapter](https://www.deeplearningbook.org/contents/autoencoders.html).
 
 _Tips & Best practices:_
 [1](https://stats.stackexchange.com/questions/257163/architecture-of-autoencoders), [2](https://stats.stackexchange.com/questions/193780/how-much-noise-for-denoising-autoencoder), [3](https://www.reddit.com/r/MachineLearning/comments/6aw8ik/d_reddit_do_you_use_autoencoders_in_practice/), [4](https://www.reddit.com/r/MachineLearning/comments/89f17m/d_current_best_practices_for_vaes/), [5](https://www.reddit.com/r/MachineLearning/comments/5k8h07/p_insights_into_variational_autoencoders_for/).
 
### Reinforcement Learning
_First look (in order):_
- [Here](https://www.youtube.com/watch?v=2pWv7GOvuf0) you have an explanation video.
- [This](https://skymind.ai/wiki/deep-reinforcement-learning) article is well explaining RL.
- [Here](https://towardsdatascience.com/what-to-expect-from-reinforcement-learning-a22e8c16f40c) is an interesting read.
- Some examples: [1](https://adventuresinmachinelearning.com/reinforcement-learning-tensorflow/), [2](https://medium.com/tensorflow/deep-reinforcement-learning-playing-cartpole-through-asynchronous-advantage-actor-critic-a3c-7eab2eea5296), [3](https://www.youtube.com/watch?v=t1A3NTttvBA), [4](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow).

_Second pass:_
[The go-to guide](https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html?utm_campaign=Data%20Machina&utm_medium=email&utm_source=Revue%20newsletter).
[Paper](https://arxiv.org/pdf/1710.02298.pdf) with state of art RL architecture.
[Complete free book on RL](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html).
 
 _Tips & Best practices:_
 [1](https://medium.com/@BonsaiAI/deep-reinforcement-learning-models-tips-tricks-for-writing-reward-functions-a84fe525e8e0), [2](https://towardsdatascience.com/applications-of-reinforcement-learning-in-real-world-1a94955bcd12).


## Utilities

**Hey You**.
During the last few years i collected tons of articles, web apps, reddit thread, best practices, projects and repositories, and I want to share with you each single bit of information, trying to organize them by type of resource (blogs or projects ideas, and so on). 

### Machine Learning Projects 

- [Enormous and awesome collection](https://github.com/FavioVazquez/ds-cheatsheets) of Data Science Cheat Sheets
- [Infinite collection](https://docs.google.com/document/d/e/2PACX-1vRRC3ZIcvjFqEYEgnN9pptoWONr2mSGZJ4hSdL8Jpf2IpXdxjTc-d3jrpb98h59xJnZ3h1frUDydoxc/pub) of actual Data Science / ML projects
- [Infinite collection](https://github.com/jtoy/awesome-tensorflow) of tutorials and Ml projects in TensorFlow
- [Other TensorFlow examples](https://github.com/aymericdamien/TensorFlow-Examples)

### Tools

- [Google Data Visualization Facets](https://pair-code.github.io/facets/)
- [Interactive Neural Network](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.95549&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)

### Youtube Channels

- [Enthought](https://www.youtube.com/user/EnthoughtMedia/videos)
- [3Blue1Brown](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw)
- [Microsoft](https://www.youtube.com/channel/UCFtEEv80fQVKkD4h1PF-Xqw)
- [TensorFlow Official channel](https://www.youtube.com/channel/UC0rqucBdTuFTjJiefW5t-IQ)
- [Engineering Man](https://www.youtube.com/channel/UCrUL8K81R4VBzm-KOYwrcxQ)
- [The Tech Lead](https://www.youtube.com/channel/UC4xKdmAXFh4ACyhpiQ_3qBw)

### Blogs 

- [How to build a data science portfolio](https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html?utm_campaign=Data%20Machina&utm_medium=email&utm_source=Revue%20newsletter)
- [Distill blog](https://distill.pub/)  
- [Keras](https://www.youtube.com/user/EnthoughtMedia/videos)
- [Paolo Galeone blog](https://pgaleone.eu/)
- [TensorFlow official blog](https://medium.com/tensorflow)
- [KD Nuggets](https://www.kdnuggets.com/)
- [Incredible Graphic explanations](http://colah.github.io/)

### Websites worth taking a look!

- [A monster collection of Data related free course](https://github.com/kmario23/deep-learning-drizzle)
- [Machine Learning Map](http://www.saedsayad.com/data_mining_map.htm) 
- [Data modeling for Business Intelligence](https://www.1keydata.com/datawarehousing/data-modeling-levels.html)
- [Statistics explained](http://www.statsoft.com/Textbook/Elementary-Statistics-Concepts#Two%20basic%20features%20of%20every%20relation%20between%20variables)
- [Visualizing data - Turorials](https://datascienceplus.com/category/visualizing-data/?tdo_tag=Python)
- [Fast.ai](https://www.fast.ai/)
- [Open.ai](https://openai.com/blog/better-language-models/)
- [Explained.ai](https://explained.ai/)
- [Machine Learning Glossary](https://developers.google.com/machine-learning/glossary/)
- [Python ML Tutorials](https://www.python-course.eu/machine_learning.php)
- [Immersive math](http://immersivemath.com/ila/)  
- [DeepLizard](http://deeplizard.com/)
- [Common Statistical Fallacies](https://www.geckoboard.com/learn/data-literacy/statistical-fallacies/)


### Subreddits you want to follow!

- [10 awesomee subreddits related to data sciece](https://www.analyticsindiamag.com/10-data-science-subreddits-every-tech-enthusiast-should-follow/)
- [An incredible tool to discover trends and subs](https://anvaka.github.io/sayit/?query=MachineLearning)

## Next Steps Roadmap

Thanks to the great success of this guide,  i've decided to expand it a lot and make more similar for different topics.
Some of the extensions i'm addig here next weeks are:

- Unsupervised Learning / Self-Suerpvised Learning
- MLOps : Machine Learning mindset framework (how to think like a data scientist)
- Data processing and preparation
- Feature Selection
- Features Engineering
- Extending the parameters optimization section
- Add a section for the Keras Library
- Add a section for the TensorFlow 2.0 
- Add a section to "How to deploy my model on AWS"
- Add a section to "How to deploy my model on Azure"



### ... Coming Very Soon! Stay tuned :)


## curated-list-of-deeplearning-blogs

* A Blog From a Human-engineer-being http://www.erogol.com/ [(RSS)](http://www.erogol.com/feed/)
* Aakash Japi http://aakashjapi.com/ [(RSS)](http://logicx24.github.io/feed.xml)
* Adit Deshpande https://adeshpande3.github.io/ [(RSS)](https://adeshpande3.github.io/adeshpande3.github.io/feed.xml)
* Advanced Analytics & R http://advanceddataanalytics.net/ [(RSS)](http://advanceddataanalytics.net/feed/)
* Adventures in Data Land http://blog.smola.org [(RSS)](http://blog.smola.org/rss)
* Agile Data Science http://blog.sense.io/ [(RSS)](http://blog.sense.io/rss/)
* Ahmed El Deeb https://medium.com/@D33B [(RSS)](https://medium.com/feed/@D33B)
* Airbnb Data blog http://nerds.airbnb.com/data/ [(RSS)](http://nerds.airbnb.com/feed/)
* Alex Castrounis | InnoArchiTech http://www.innoarchitech.com/ [(RSS)](http://www.innoarchitech.com/feed.xml)
* Alex Perrier http://alexperrier.github.io/ [(RSS)](http://alexperrier.github.io/feed.xml)
* Algobeans | Data Analytics Tutorials & Experiments for the Layman https://algobeans.com [(RSS)](https://algobeans.com/feed/)
* Amazon AWS AI Blog https://aws.amazon.com/blogs/ai/ [(RSS)](https://aws.amazon.com/blogs/amazon-ai/feed/)
* Analytics Vidhya http://www.analyticsvidhya.com/blog/ [(RSS)](http://feeds.feedburner.com/AnalyticsVidhya)
* Analytics and Visualization in Big Data @ Sicara https://blog.sicara.com [(RSS)](https://blog.sicara.com/feed)
* Andreas Müller http://peekaboo-vision.blogspot.com/ [(RSS)](http://peekaboo-vision.blogspot.com/atom.xml)
* Andrej Karpathy blog http://karpathy.github.io/ [(RSS)](http://karpathy.github.io/feed.xml)
* Andrew Brooks http://brooksandrew.github.io/simpleblog/ [(RSS)](http://brooksandrew.github.io/simpleblog/feed.xml)
* Andrey Kurenkov http://www.andreykurenkov.com/writing/ [(RSS)](http://www.andreykurenkov.com/writing/feed.xml/)
* Anton Lebedevich's Blog http://mabrek.github.io/ [(RSS)](http://mabrek.github.io/feed.xml)
* Arthur Juliani https://medium.com/@awjuliani [(RSS)](https://medium.com/feed/@awjuliani)
* Audun M. Øygard http://www.auduno.com/ [(RSS)](http://auduno.tumblr.com/rss)
* Avi Singh https://avisingh599.github.io/ [(RSS)](http://avisingh599.github.io/feed.xml)
* Beautiful Data http://beautifuldata.net/ [(RSS)](http://beautifuldata.net/feed/)
* Beckerfuffle http://mdbecker.github.io/ [(RSS)](http://mdbecker.github.io/atom.xml)
* Becoming A Data Scientist http://www.becomingadatascientist.com/ [(RSS)](http://www.becomingadatascientist.com/feed/)
* Ben Bolte's Blog http://benjaminbolte.com/ml/ [(RSS)](http://benjaminbolte.com/ml/)
* Ben Frederickson http://www.benfrederickson.com/blog/ [(RSS)](http://www.benfrederickson.com/atom.xml)
* Berkeley AI Research http://bair.berkeley.edu/blog/ [(RSS)](http://bair.berkeley.edu/blog/feed.xml)
* Big-Ish Data http://bigishdata.com/ [(RSS)](http://bigishdata.com/feed/)
* Blog on neural networks http://yerevann.github.io/ [(RSS)](http://yerevann.github.io/atom.xml)
* Blogistic RegressionAbout Projects http://d10genes.github.io/blog/ [(RSS)](http://d10genes.github.io/blog/feed.xml)
* blogR | R tips and tricks from a scientist https://drsimonj.svbtle.com/ [(RSS)](https://drsimonj.svbtle.com/)
* Brain of mat kelcey http://matpalm.com/blog/ [(RSS)](http://matpalm.com/blog/feed)
* Brilliantly wrong thoughts on science and programming https://arogozhnikov.github.io/ [(RSS)](http://arogozhnikov.github.io/feed.xml)
* Bugra Akyildiz http://bugra.github.io/ [(RSS)](http://bugra.github.io/feeds/all.atom.xml)
* Building Babylon https://building-babylon.net/ [(RSS)](http://building-babylon.net/feed/)
* Carl Shan http://carlshan.com/ [(RSS)](http://feeds.feedburner.com/carlshan)
* Chris Stucchio https://www.chrisstucchio.com/blog/index.html [(RSS)](http://www.chrisstucchio.com/blog/atom.xml)
* Christophe Bourguignat https://medium.com/@chris_bour [(RSS)](https://medium.com/feed/@chris_bour)
* Christopher Nguyen https://medium.com/@ctn [(RSS)](https://medium.com/feed/@ctn)
* Cloudera Data Science Posts http://blog.cloudera.com/blog/category/data-science/ [(RSS)](http://blog.cloudera.com/blog/category/data-science/feed/)
* colah's blog http://colah.github.io/archive.html [(RSS)](http://colah.github.io/rss.xml)
* Cortana Intelligence and Machine Learning Blog https://blogs.technet.microsoft.com/machinelearning/ [(RSS)](http://blogs.technet.com/b/machinelearning/rss.aspx)
* Daniel Forsyth http://www.danielforsyth.me/ [(RSS)](http://www.danielforsyth.me/rss/)
* Daniel Homola http://danielhomola.com/category/blog/ [(RSS)](http://danielhomola.com/feed/)
* Daniel Nee http://danielnee.com [(RSS)](http://danielnee.com/?feed=rss2)
* Data Based Inventions http://datalab.lu/ [(RSS)](http://datalab.lu/atom.xml)
* Data Blogger https://www.data-blogger.com/ [(RSS)](https://www.data-blogger.com/feed/)
* Data Labs http://blog.insightdatalabs.com/ [(RSS)](http://blog.insightdatalabs.com/rss/)
* Data Meets Media http://datameetsmedia.com/ [(RSS)](http://datameetsmedia.com/feed/)
* Data Miners Blog http://blog.data-miners.com/ [(RSS)](http://blog.data-miners.com/feeds/posts/default?alt=rss)
* Data Mining Research http://www.dataminingblog.com/ [(RSS)](http://feeds.feedburner.com/dataminingblog)
* Data Mining: Text Mining, Visualization and Social Media http://datamining.typepad.com/data_mining/ [(RSS)](http://datamining.typepad.com/data_mining/atom.xml)
* Data Piques http://blog.ethanrosenthal.com/ [(RSS)](http://blog.ethanrosenthal.com/feeds/all.atom.xml)
* Data School http://www.dataschool.io/ [(RSS)](http://www.dataschool.io/rss/)
* Data Science 101 http://101.datascience.community/ [(RSS)](http://101.datascience.community/feed/)
* Data Science @ Facebook https://research.facebook.com/blog/datascience/ [(RSS)](https://research.facebook.com/blog/datascience/)
* Data Science Insights http://www.datasciencebowl.com/data-science-insights/ [(RSS)](http://www.datasciencebowl.com/feed/)
* Data Science Tutorials https://codementor.io/data-science/tutorial [(RSS)](https://www.codementor.io/data-science/tutorial/feed)
* Data Science Vademecum http://datasciencevademecum.wordpress.com/ [(RSS)](http://datasciencevademecum.wordpress.com/feed/)
* Dataaspirant http://dataaspirant.com/ [(RSS)](http://dataaspirant.wordpress.com/feed/)
* Dataclysm http://blog.okcupid.com/ [(RSS)](http://blog.okcupid.com/index.php/feed/)
* DataGenetics http://datagenetics.com/blog.html [(RSS)](http://datagenetics.com/feed/rss.xml)
* Dataiku https://www.dataiku.com/blog/ [(RSS)](http://www.dataiku.com/feed.xml)
* DataKind http://www.datakind.org/blog [(RSS)](http://feeds.feedburner.com/DataKin)
* DataLook http://blog.datalook.io/ [(RSS)](http://blog.datalook.io/feed/)
* Datanice https://datanice.wordpress.com/ [(RSS)](https://datanice.wordpress.com/feed/)
* Dataquest Blog https://www.dataquest.io/blog/ [(RSS)](https://www.dataquest.io/blog/atom.xml)
* DataRobot http://www.datarobot.com/blog/ [(RSS)](http://www.datarobot.com/feed/)
* Datascope http://datascopeanalytics.com/blog [(RSS)](http://datascopeanalytics.com/rss)
* DatasFrame http://tomaugspurger.github.io/ [(RSS)](http://tomaugspurger.github.io/feeds/all.rss.xml)
* David Mimno http://www.mimno.org/ [(RSS)](http://mimno.infosci.cornell.edu/b/feed.xml)
* Dayne Batten http://daynebatten.com [(RSS)](http://daynebatten.com/feed/)
* Deep Learning http://deeplearning.net/blog/ [(RSS)](http://deeplearning.net/feed/)
* Deepdish http://deepdish.io/ [(RSS)](http://deepdish.io/atom.xml)
* Delip Rao http://deliprao.com/ [(RSS)](http://deliprao.com/feed)
* DENNY'S BLOG http://blog.dennybritz.com/ [(RSS)](http://blog.dennybritz.com/feed/)
* Dimensionless https://dimensionless.in/blog/ [(RSS)](https://dimensionless.in/feed)
* Distill http://distill.pub/ [(RSS)](http://distill.pub/rss.xml)
* District Data Labs http://districtdatalabs.silvrback.com/ [(RSS)](https://districtdatalabs.silvrback.com/feed)
* Diving into data https://blog.datadive.net/ [(RSS)](http://blog.datadive.net/feed/)
* Domino Data Lab's blog http://blog.dominodatalab.com/ [(RSS)](http://blog.dominodatalab.com/rss/)
* Dr. Randal S. Olson http://www.randalolson.com/blog/ [(RSS)](http://www.randalolson.com/feed/)
* Drew Conway https://medium.com/@drewconway [(RSS)](https://medium.com/feed/@drewconway)
* Dustin Tran http://dustintran.com/blog/ [(RSS)](http://dustintran.com/blog/rss/)
* Eder Santana https://edersantana.github.io/blog.html [(RSS)](http://edersantana.github.io/feed.xml)
* Edwin Chen http://blog.echen.me [(RSS)](http://blog.echen.me/feeds/all.rss.xml)
* EFavDB http://efavdb.com/ [(RSS)](http://efavdb.com/feed/)
* Emilio Ferrara, Ph.D.  http://www.emilio.ferrara.name/ [(RSS)](http://www.emilio.ferrara.name/feed/)
* Entrepreneurial Geekiness http://ianozsvald.com/ [(RSS)](http://ianozsvald.com/feed/)
* Eric Jonas http://ericjonas.com/archives.html [(RSS)](http://ericjonas.com/archives.html)
* Eric Siegel http://www.predictiveanalyticsworld.com/blog [(RSS)](http://feeds.feedburner.com/predictiveanalyticsworld/GXRy)
* Erik Bern http://erikbern.com [(RSS)](http://erikbern.com/feed/)
* ERIN SHELLMAN http://www.erinshellman.com/ [(RSS)](http://www.erinshellman.com/feed/)
* Eugenio Culurciello http://culurciello.github.io/ [(RSS)](http://culurciello.github.io/feed.xml)
* Fabian Pedregosa http://fa.bianp.net/ [(RSS)](http://fa.bianp.net/blog/feed/)
* Fast Forward Labs http://blog.fastforwardlabs.com/ [(RSS)](http://blog.fastforwardlabs.com/rss)
* FastML http://fastml.com/ [(RSS)](http://fastml.com/atom.xml)
* Florian Hartl http://florianhartl.com/ [(RSS)](http://florianhartl.com/feed/)
* FlowingData http://flowingdata.com/ [(RSS)](http://flowingdata.com/feed/)
* Full Stack ML http://fullstackml.com/ [(RSS)](http://fullstackml.com/feed/)
* GAB41 http://www.lab41.org/gab41/ [(RSS)](http://www.lab41.org/feed/)
* Garbled Notes http://www.chioka.in/ [(RSS)](http://www.chioka.in/feed.xml)
* Greg Reda http://www.gregreda.com/blog/ [(RSS)](http://www.gregreda.com/feeds/all.atom.xml)
* Hyon S Chu https://medium.com/@adailyventure [(RSS)](https://medium.com/feed/@adailyventure)
* i am trask http://iamtrask.github.io/ [(RSS)](http://iamtrask.github.io/feed.xml)
* I Quant NY http://iquantny.tumblr.com/ [(RSS)](http://iquantny.tumblr.com/rss)
* inFERENCe http://www.inference.vc/ [(RSS)](http://www.inference.vc/rss/)
* Insight Data Science https://blog.insightdatascience.com/ [(RSS)](https://blog.insightdatascience.com/feed)
* INSPIRATION INFORMATION http://myinspirationinformation.com/ [(RSS)](http://myinspirationinformation.com/feed/)
* Ira Korshunova http://irakorshunova.github.io/ [(RSS)](http://irakorshunova.github.io/feed.xml)
* I’m a bandit https://blogs.princeton.edu/imabandit/ [(RSS)](https://blogs.princeton.edu/imabandit/feed/)
* Jason Toy http://www.jtoy.net/ [(RSS)](http://jtoy.net/atom.xml)
* Jeremy D. Jackson, PhD http://www.jeremydjacksonphd.com/ [(RSS)](http://www.jeremydjacksonphd.com/?feed=rss2)
* Jesse Steinweg-Woods https://jessesw.com/ [(RSS)](https://jessesw.com/feed.xml)
* Joe Cauteruccio http://www.joecjr.com/ [(RSS)](http://www.joecjr.com/feed/)
* John Myles White http://www.johnmyleswhite.com/ [(RSS)](http://www.johnmyleswhite.com/feed/)
* John's Soapbox http://joschu.github.io/ [(RSS)](http://joschu.github.io/feed.xml)
* Jonas Degrave http://317070.github.io/ [(RSS)](http://317070.github.io/feed.xml)
* Joy Of Data http://www.joyofdata.de/blog/ [(RSS)](http://www.joyofdata.de/blog/feed/)
* Julia Evans http://jvns.ca/ [(RSS)](http://jvns.ca/atom.xml)
* KDnuggets http://www.kdnuggets.com/ [(RSS)](http://feeds.feedburner.com/kdnuggets-data-mining-analytics)
* Keeping Up With The Latest Techniques http://colinpriest.com/ [(RSS)](http://colinpriest.com/feed/)
* Kenny Bastani http://www.kennybastani.com/ [(RSS)](http://www.kennybastani.com/feeds/posts/default?alt=rss)
* Kevin Davenport http://kldavenport.com/ [(RSS)](http://kldavenport.com/feed/)
* kevin frans http://kvfrans.com/ [(RSS)](http://kvfrans.com/rss/)
* korbonits | Math ∩ Data http://korbonits.github.io/ [(RSS)](http://korbonits.github.io/feed.xml)
* Large Scale Machine Learning  http://bickson.blogspot.com/ [(RSS)](http://bickson.blogspot.com/feeds/posts/default)
* LATERAL BLOG https://blog.lateral.io/ [(RSS)](https://blog.lateral.io/feed/)
* Lazy Programmer http://lazyprogrammer.me/ [(RSS)](http://lazyprogrammer.me/feed/)
* Learn Analytics Here https://learnanalyticshere.wordpress.com/ [(RSS)](https://learnanalyticshere.wordpress.com/feed/)
* LearnDataSci http://www.learndatasci.com/ [(RSS)](http://www.learndatasci.com/feed/)
* Learning With Data http://learningwithdata.com/ [(RSS)](http://learningwithdata.com/rss_feed.xml)
* Life, Language, Learning http://daoudclarke.github.io/ [(RSS)](http://daoudclarke.github.io/atom.xml)
* Locke Data https://itsalocke.com/blog/ [(RSS)](https://itsalocke.com/feed)
* Louis Dorard http://www.louisdorard.com/blog/ [(RSS)](http://www.louisdorard.com/blog?format=rss)
* M.E.Driscoll http://medriscoll.com/ [(RSS)](http://medriscoll.com/rss)
* Machinalis http://www.machinalis.com/blog [(RSS)](http://www.machinalis.com/blog/feeds/rss/)
* Machine Learning (Theory) http://hunch.net/ [(RSS)](http://hunch.net/?feed=rss2)
* Machine Learning and Data Science http://alexhwoods.com/blog/ [(RSS)](http://alexhwoods.com/feed/)
* Machine Learning https://charlesmartin14.wordpress.com/ [(RSS)](http://charlesmartin14.wordpress.com/feed/)
* Machine Learning Mastery http://machinelearningmastery.com/blog/ [(RSS)](http://machinelearningmastery.com/feed/)
* Machine Learning Blogs https://machinelearningblogs.com/ [(RSS)](https://machinelearningblogs.com/feed/)
* Machine Learning, etc http://yaroslavvb.blogspot.com [(RSS)](http://yaroslavvb.blogspot.com/feeds/posts/default)
* Machine Learning, Maths and Physics https://mlopezm.wordpress.com/ [(RSS)](https://mlopezm.wordpress.com/feed/)
* Machine Learning Flashcards https://machinelearningflashcards.com/ $10, but a nicely illustrated set of 300 flash cards
* Machined Learnings http://www.machinedlearnings.com/ [(RSS)](http://www.machinedlearnings.com/feeds/posts/default)
* MAPPING BABEL https://jack-clark.net/ [(RSS)](https://jack-clark.net/feed/)
* MAPR Blog https://www.mapr.com/blog [(RSS)](https://www.mapr.com/bigdata.xml)
* MAREK REI http://www.marekrei.com/blog/ [(RSS)](http://www.marekrei.com/blog/feed/)
* MARGINALLY INTERESTING http://blog.mikiobraun.de/ [(RSS)](http://feeds.feedburner.com/MarginallyInteresting)
* Math ∩ Programming http://jeremykun.com/ [(RSS)](http://jeremykun.wordpress.com/feed/)
* Matthew Rocklin http://matthewrocklin.com/blog/ [(RSS)](http://matthewrocklin.com/blog/atom.xml)
* Melody Wolk http://melodywolk.com/projects/ [(RSS)](http://melodywolk.com/feed/)
* Mic Farris http://www.micfarris.com/ [(RSS)](http://www.micfarris.com/feed/)
* Mike Tyka http://mtyka.github.io/ [(RSS)](http://mtyka.github.io//feed.xml)
* minimaxir | Max Woolf's Blog http://minimaxir.com/ [(RSS)](http://minimaxir.com/rss.xml)
* Mirror Image https://mirror2image.wordpress.com/ [(RSS)](http://mirror2image.wordpress.com/feed/)
* Mitch Crowe http://www.dataphoric.com/ [(RSS)](http://www.dataphoric.com/feed.xml)
* MLWave http://mlwave.com/ [(RSS)](http://mlwave.com/feed/)
* MLWhiz http://mlwhiz.com/ [(RSS)](http://mlwhiz.com/atom.xml)
* Models are illuminating and wrong https://peadarcoyle.wordpress.com/ [(RSS)](http://peadarcoyle.wordpress.com/feed/)
* Moody Rd http://blog.mrtz.org/ [(RSS)](http://blog.mrtz.org/feed.xml)
* Moonshots http://jxieeducation.com/ [(RSS)](http://jxieeducation.com/feed.xml)
* Mourad Mourafiq http://mourafiq.com/ [(RSS)](http://mourafiq.com/atom.xml)
* My thoughts on Data science, predictive analytics, Python http://shahramabyari.com/ [(RSS)](http://shahramabyari.com/feed/)
* Natural language processing blog http://nlpers.blogspot.fr/ [(RSS)](http://nlpers.blogspot.com/feeds/posts/default)
* Neil Lawrence http://inverseprobability.com/blog.html [(RSS)](http://inverseprobability.com/rss.xml)
* NLP and Deep Learning enthusiast http://camron.xyz/ [(RSS)](http://camron.xyz/index.php/feed/)
* no free hunch http://blog.kaggle.com/ [(RSS)](http://blog.kaggle.com/feed/)
* Nuit Blanche http://nuit-blanche.blogspot.com/ [(RSS)](http://nuit-blanche.blogspot.com/feeds/posts/default)
* Number 2147483647 https://no2147483647.wordpress.com/ [(RSS)](http://no2147483647.wordpress.com/feed/)
* On Machine Intelligence https://aimatters.wordpress.com/ [(RSS)](https://aimatters.wordpress.com/feed/)
* Opiate for the masses Data is our religion. http://opiateforthemass.es/ [(RSS)](http://opiateforthemass.es/feed.xml)
* p-value.info http://www.p-value.info/ [(RSS)](http://www.p-value.info/feeds/posts/default)
* Pete Warden's blog http://petewarden.com/ [(RSS)](http://feeds.feedburner.com/typepad/petewarden)
* Plotly Blog http://blog.plot.ly/ [(RSS)](http://blog.plot.ly/rss)
* Probably Overthinking It http://allendowney.blogspot.ca/ [(RSS)](http://allendowney.blogspot.com/feeds/posts/default)
* Prooffreader.com http://www.prooffreader.com [(RSS)](http://www.prooffreader.com/feeds/posts/default)
* ProoffreaderPlus http://prooffreaderplus.blogspot.ca/ [(RSS)](http://prooffreaderplus.blogspot.ca/feeds/posts/default)
* Publishable Stuff http://www.sumsar.net/ [(RSS)](http://www.sumsar.net/atom.xml)
* PyImageSearch http://www.pyimagesearch.com/ [(RSS)](http://feeds.feedburner.com/Pyimagesearch)
* Pythonic Perambulations https://jakevdp.github.io/ [(RSS)](http://jakevdp.github.com/atom.xml)
* quintuitive http://quintuitive.com/ [(RSS)](http://quintuitive.com/feed/)
* R and Data Mining https://rdatamining.wordpress.com/ [(RSS)](http://rdatamining.wordpress.com/feed/)
* R-bloggers http://www.r-bloggers.com/ [(RSS)](http://feeds.feedburner.com/RBloggers)
* R2RT http://r2rt.com/ [(RSS)](http://r2rt.com/feeds/all.atom.xml)
* Ramiro Gómez http://ramiro.org/notebooks/ [(RSS)](http://ramiro.org/notebook/rss.xml)
* Random notes on Computer Science, Mathematics and Software Engineering http://barmaley-exe.github.io/ [(RSS)](http://feeds.feedburner.com/barmaley-exe-blog-feed)
* Randy Zwitch http://randyzwitch.com/ [(RSS)](http://randyzwitch.com/feed.xml)
* RaRe Technologies http://rare-technologies.com/blog/ [(RSS)](http://rare-technologies.com/feed/)
* Rayli.Net http://rayli.net/blog/ [(RSS)](http://rayli.net/blog/feed/)
* Revolutions http://blog.revolutionanalytics.com/ [(RSS)](http://blog.revolutionanalytics.com/atom.xml)
* Rinu Boney http://rinuboney.github.io/ [(RSS)](http://rinuboney.github.io/feed.xml)
* RNDuja Blog http://rnduja.github.io/ [(RSS)](http://rnduja.github.io/feed.xml)
* Robert Chang https://medium.com/@rchang [(RSS)](https://medium.com/feed/@rchang)
* Rocket-Powered Data Science http://rocketdatascience.org [(RSS)](http://rocketdatascience.org/?feed=rss2)
* Sachin Joglekar's blog https://codesachin.wordpress.com/ [(RSS)](https://codesachin.wordpress.com/feed/)
* samim https://medium.com/@samim [(RSS)](https://medium.com/feed/@samim)
* Sean J. Taylor http://seanjtaylor.com/ [(RSS)](http://seanjtaylor.com/rss)
* Sebastian Raschka http://sebastianraschka.com/blog/index.html [(RSS)](http://sebastianraschka.com/rss_feed.xml)
* Sebastian Ruder http://sebastianruder.com/ [(RSS)](http://sebastianruder.com/rss/)
* Sebastian's slow blog http://www.nowozin.net/sebastian/blog/ [(RSS)](http://www.nowozin.net/sebastian/blog/feeds/all.atom.xml)
* SFL Scientific Blog https://sflscientific.com/blog/ [(RSS)](http://sflscientific.com/blog/?format=rss)
* Shakir's Machine Learning Blog http://blog.shakirm.com/ [(RSS)](http://blog.shakirm.com/feed/)
* Simply Statistics http://simplystatistics.org [(RSS)](http://simplystatistics.org/feed/)
* Springboard Blog http://springboard.com/blog
* Startup.ML Blog http://startup.ml/blog [(RSS)](http://www.startup.ml/blog?format=RSS)
* Statistical Modeling, Causal Inference, and Social Science http://andrewgelman.com/ [(RSS)](http://andrewgelman.com/feed/)
* Stigler Diet http://stiglerdiet.com/ [(RSS)](http://stiglerdiet.com/feeds/all.atom.xml)
* Stitch Fix Tech Blog http://multithreaded.stitchfix.com/blog/ [(RSS)](http://multithreaded.stitchfix.com/feed.xml)
* Stochastic R&D Notes http://arseny.info/ [(RSS)](http://arseny.info/feeds/all.rss.xml)
* Storytelling with Statistics on Quora http://datastories.quora.com/ [(RSS)](http://datastories.quora.com/rss)
* StreamHacker http://streamhacker.com/ [(RSS)](http://feeds.feedburner.com/StreamHacker)
* Subconscious Musings http://blogs.sas.com/content/subconsciousmusings/ [(RSS)](http://feeds.feedburner.com/advanalytics)
* Swan Intelligence http://swanintelligence.com/ [(RSS)](http://swanintelligence.com/feeds/all.rss.xml)
* TechnoCalifornia http://technocalifornia.blogspot.se/ [(RSS)](http://technocalifornia.blogspot.com/feeds/posts/default)
* TEXT ANALYSIS BLOG | AYLIEN http://blog.aylien.com/ [(RSS)](http://blog.aylien.com/rss)
* The Angry Statistician http://angrystatistician.blogspot.com/ [(RSS)](http://angrystatistician.blogspot.com/feeds/posts/default)
* The Clever Machine https://theclevermachine.wordpress.com/ [(RSS)](http://theclevermachine.wordpress.com/feed/)
* The Data Camp Blog https://www.datacamp.com/community/blog [(RSS)](http://blog.datacamp.com/feed/)
* The Data Incubator http://blog.thedataincubator.com/ [(RSS)](http://blog.thedataincubator.com/feed/)
* The Data Science Lab https://datasciencelab.wordpress.com/ [(RSS)](http://datasciencelab.wordpress.com/feed/)
* THE ETZ-FILES http://alexanderetz.com/ [(RSS)](http://nicebrain.wordpress.com/feed/)
* The Science of Data http://www.martingoodson.com [(RSS)](http://www.martingoodson.com/rss/)
* The Shape of Data https://shapeofdata.wordpress.com [(RSS)](https://shapeofdata.wordpress.com/feed/)
* The unofficial Google data science Blog http://www.unofficialgoogledatascience.com/ [(RSS)](http://www.unofficialgoogledatascience.com/feeds/posts/default)
* Tim Dettmers http://timdettmers.com/ [(RSS)](http://timdettmers.com/feed/)
* Tombone's Computer Vision Blog http://www.computervisionblog.com/ [(RSS)](http://www.computervisionblog.com/feeds/posts/default)
* Tommy Blanchard http://tommyblanchard.com/category/projects [(RSS)](http://tommyblanchard.com/feeds/all.atom.xml)
* Trevor Stephens http://trevorstephens.com/ [(RSS)](http://trevorstephens.com/feed.xml)
* Trey Causey http://treycausey.com/ [(RSS)](http://treycausey.com/feeds/all.atom.xml)
* UW Data Science Blog http://datasciencedegree.wisconsin.edu/blog/ [(RSS)](http://datasciencedegree.wisconsin.edu/feed/)
* Wellecks http://wellecks.wordpress.com/ [(RSS)](http://wellecks.wordpress.com/feed/)
* Wes McKinney http://wesmckinney.com/archives.html [(RSS)](http://wesmckinney.com/feeds/all.atom.xml)
* While My MCMC Gently Samples http://twiecki.github.io/ [(RSS)](http://twiecki.github.io/atom.xml)
* WildML http://www.wildml.com/ [(RSS)](http://www.wildml.com/feed/)
* Will do stuff for stuff http://rinzewind.org/blog-en [(RSS)](http://rinzewind.org/feed-en)
* Will wolf http://willwolf.io/ [(RSS)](http://willwolf.io/feed/)
* WILL'S NOISE http://www.willmcginnis.com/ [(RSS)](http://www.willmcginnis.com/feed/)
* William Lyon http://www.lyonwj.com/ [(RSS)](http://www.lyonwj.com/atom.xml)
* Win-Vector Blog http://www.win-vector.com/blog/ [(RSS)](http://www.win-vector.com/blog/feed/)
* Yanir Seroussi http://yanirseroussi.com/ [(RSS)](http://yanirseroussi.com/feed/)
* Zac Stewart http://zacstewart.com/ [(RSS)](http://zacstewart.com/feed.xml)
* ŷhat http://blog.yhat.com/ [(RSS)](http://blog.yhat.com/rss.xml)
* ℚuantitative √ourney http://outlace.com/ [(RSS)](http://outlace.com/feed.xml)
* 大トロ http://blog.otoro.net/ [(RSS)](http://blog.otoro.net/feed.xml)


## credits

* [Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793) by Wes McKinney
* [PyCon 2015 Scikit-learn Tutorial](https://github.com/jakevdp/sklearn_pycon2015) by Jake VanderPlas
* [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook) by Jake VanderPlas
* [Parallel Machine Learning with scikit-learn and IPython](https://github.com/ogrisel/parallel_ml_tutorial) by Olivier Grisel
* [Statistical Interference Using Computational Methods in Python](https://github.com/AllenDowney/CompStats) by Allen Downey
* [TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples) by Aymeric Damien
* [TensorFlow Tutorials](https://github.com/pkmital/tensorflow_tutorials) by Parag K Mital
* [TensorFlow Tutorials](https://github.com/nlintz/TensorFlow-Tutorials) by Nathan Lintz
* [TensorFlow Tutorials](https://github.com/alrojo/tensorflow-tutorial) by Alexander R Johansen
* [TensorFlow Book](https://github.com/BinRoot/TensorFlow-Book) by Nishant Shukla
* [Summer School 2015](https://github.com/mila-udem/summerschool2015) by mila-udem
* [Keras tutorials](https://github.com/leriomaggio/deep-learning-keras-tensorflow) by Valerio Maggio
* [Kaggle](https://www.kaggle.com/)
* [Yhat Blog](http://blog.yhat.com/)

## contributing

Contributions are welcome!  For bug reports or requests please [submit an issue](https://github.com/tarrysingh/Machine-Learning-Tutorials//issues).

## contact-info

Feel free to contact me to discuss any issues, questions, or comments.

* Email: [tarry.singh@gmail.com](mailto:tarry.singh@gmail.com)
* Twitter: [@tarrysingh](https://twitter.com/tarrysingh)
* GitHub: [tarrysingh](https://github.com/tarrysingh.com)
* LinkedIn: [Tarry Singh](https://www.linkedin.com/in/tarrysingh)
* Website: [tarrysingh.com](https://tarrysingh.com)
* Medium: [tarry@Medium](https://medium.com/@tarrysingh)
* Quora : [Answers from Tarry on Quora](https://www.quora.com/profile/Tarry-Singh)

## license

This repository contains a variety of content; some developed by Tarry Singh and some from third-parties and a lot will be maintained by me. The third-party content is distributed under the license provided by those parties.

The content was originally developed by Donne Martin is distributed under the following license. I will be maintaining and revamping it by adding PyTorch, Torch/Lua, MXNET and much more:

*I am providing code and resources in this repository to you under an open source license.*

    Copyright 2017 Tarry Singh

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
